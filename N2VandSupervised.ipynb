{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1,\n",
    "            padding=1, bias=True, groups=1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        bias=bias,\n",
    "        groups=groups)\n",
    "\n",
    "def upconv2x2(in_channels, out_channels, mode='transpose'):\n",
    "    if mode == 'transpose':\n",
    "        return nn.ConvTranspose2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=2,\n",
    "            stride=2)\n",
    "    else:\n",
    "        # out_channels is always going to be the same\n",
    "        # as in_channels\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "            conv1x1(in_channels, out_channels))\n",
    "\n",
    "def conv1x1(in_channels, out_channels, groups=1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=1,\n",
    "        groups=groups,\n",
    "        stride=1)\n",
    "\n",
    "\n",
    "class DownConv(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 convolutions and 1 MaxPool.\n",
    "    A ReLU activation follows each convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, pooling=True):\n",
    "        super(DownConv, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.pooling = pooling\n",
    "\n",
    "        self.conv1 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "        if self.pooling:\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        before_pool = x\n",
    "        if self.pooling:\n",
    "            x = self.pool(x)\n",
    "        return x, before_pool\n",
    "\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 convolutions and 1 UpConvolution.\n",
    "    A ReLU activation follows each convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 merge_mode='concat', up_mode='transpose'):\n",
    "        super(UpConv, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.merge_mode = merge_mode\n",
    "        self.up_mode = up_mode\n",
    "\n",
    "        self.upconv = upconv2x2(self.in_channels, self.out_channels,\n",
    "            mode=self.up_mode)\n",
    "\n",
    "        if self.merge_mode == 'concat':\n",
    "            self.conv1 = conv3x3(\n",
    "                2*self.out_channels, self.out_channels)\n",
    "        else:\n",
    "            # num of input channels to conv2 is same\n",
    "            self.conv1 = conv3x3(self.out_channels, self.out_channels)\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, from_down, from_up):\n",
    "        \"\"\" Forward pass\n",
    "        Arguments:\n",
    "            from_down: tensor from the encoder pathway\n",
    "            from_up: upconv'd tensor from the decoder pathway\n",
    "        \"\"\"\n",
    "        from_up = self.upconv(from_up)\n",
    "        if self.merge_mode == 'concat':\n",
    "            x = torch.cat((from_up, from_down), 1)\n",
    "        else:\n",
    "            x = from_up + from_down\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\" `UNet` class is based on https://arxiv.org/abs/1505.04597\n",
    "    The U-Net is a convolutional encoder-decoder neural network.\n",
    "    Contextual spatial information (from the decoding,\n",
    "    expansive pathway) about an input tensor is merged with\n",
    "    information representing the localization of details\n",
    "    (from the encoding, compressive pathway).\n",
    "    Modifications to the original paper:\n",
    "    (1) padding is used in 3x3 convolutions to prevent loss\n",
    "        of border pixels\n",
    "    (2) merging outputs does not require cropping due to (1)\n",
    "    (3) residual connections can be used by specifying\n",
    "        UNet(merge_mode='add')\n",
    "    (4) if non-parametric upsampling is used in the decoder\n",
    "        pathway (specified by upmode='upsample'), then an\n",
    "        additional 1x1 2d convolution occurs after upsampling\n",
    "        to reduce channel dimensionality by a factor of 2.\n",
    "        This channel halving happens with the convolution in\n",
    "        the tranpose convolution (specified by upmode='transpose')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, in_channels=1, depth=5,\n",
    "                 start_filts=64, up_mode='transpose',\n",
    "                 merge_mode='add'):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            in_channels: int, number of channels in the input tensor.\n",
    "                Default is 3 for RGB images.\n",
    "            depth: int, number of MaxPools in the U-Net.\n",
    "            start_filts: int, number of convolutional filters for the\n",
    "                first conv.\n",
    "            up_mode: string, type of upconvolution. Choices: 'transpose'\n",
    "                for transpose convolution or 'upsample' for nearest neighbour\n",
    "                upsampling.\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        if up_mode in ('transpose', 'upsample'):\n",
    "            self.up_mode = up_mode\n",
    "        else:\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for \"\n",
    "                             \"upsampling. Only \\\"transpose\\\" and \"\n",
    "                             \"\\\"upsample\\\" are allowed.\".format(up_mode))\n",
    "\n",
    "        if merge_mode in ('concat', 'add'):\n",
    "            self.merge_mode = merge_mode\n",
    "        else:\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for\"\n",
    "                             \"merging up and down paths. \"\n",
    "                             \"Only \\\"concat\\\" and \"\n",
    "                             \"\\\"add\\\" are allowed.\".format(up_mode))\n",
    "\n",
    "        # NOTE: up_mode 'upsample' is incompatible with merge_mode 'add'\n",
    "        if self.up_mode == 'upsample' and self.merge_mode == 'add':\n",
    "            raise ValueError(\"up_mode \\\"upsample\\\" is incompatible \"\n",
    "                             \"with merge_mode \\\"add\\\" at the moment \"\n",
    "                             \"because it doesn't make sense to use \"\n",
    "                             \"nearest neighbour to reduce \"\n",
    "                             \"depth channels (by half).\")\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.start_filts = start_filts\n",
    "        self.depth = depth\n",
    "\n",
    "        self.down_convs = []\n",
    "        self.up_convs = []\n",
    "        \n",
    "        self.noiseSTD = nn.Parameter(data=torch.log(torch.tensor(0.5)))\n",
    "        \n",
    "        \n",
    "\n",
    "        # create the encoder pathway and add to a list\n",
    "        for i in range(depth):\n",
    "            ins = self.in_channels if i == 0 else outs\n",
    "            outs = self.start_filts*(2**i)\n",
    "            pooling = True if i < depth-1 else False\n",
    "\n",
    "            down_conv = DownConv(ins, outs, pooling=pooling)\n",
    "            self.down_convs.append(down_conv)\n",
    "\n",
    "        # create the decoder pathway and add to a list\n",
    "        # - careful! decoding only requires depth-1 blocks\n",
    "        for i in range(depth-1):\n",
    "            ins = outs\n",
    "            outs = ins // 2\n",
    "            up_conv = UpConv(ins, outs, up_mode=up_mode,\n",
    "                merge_mode=merge_mode)\n",
    "            self.up_convs.append(up_conv)\n",
    "\n",
    "        self.conv_final = conv1x1(outs, self.num_classes)\n",
    "\n",
    "        # add the list of modules to current module\n",
    "        self.down_convs = nn.ModuleList(self.down_convs)\n",
    "        self.up_convs = nn.ModuleList(self.up_convs)\n",
    "\n",
    "        self.reset_params()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_normal(m.weight)\n",
    "            init.constant(m.bias, 0)\n",
    "\n",
    "\n",
    "    def reset_params(self):\n",
    "        for i, m in enumerate(self.modules()):\n",
    "            self.weight_init(m)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_outs = []\n",
    "\n",
    "        # encoder pathway, save outputs for merging\n",
    "        for i, module in enumerate(self.down_convs):\n",
    "            x, before_pool = module(x)\n",
    "            encoder_outs.append(before_pool)\n",
    "\n",
    "        for i, module in enumerate(self.up_convs):\n",
    "            before_pool = encoder_outs[-(i+2)]\n",
    "            x = module(before_pool, x)\n",
    "\n",
    "        # No softmax is used. This means you need to use\n",
    "        # nn.CrossEntropyLoss is your training script,\n",
    "        # as this module includes a softmax already.\n",
    "        x = self.conv_final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many functions we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"CUDA?\",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def normalDens(x,m_=0.0,std_=None):\n",
    "    tmp=-((x-m_)**2) \n",
    "    tmp=tmp / (2.0*std_*std_)\n",
    "    tmp= torch.exp(tmp )\n",
    "    tmp= tmp/ torch.sqrt( (2.0*np.pi)*std_*std_)\n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"CUDA?\",torch.cuda.is_available())\n",
    "\n",
    "\n",
    "def imgToTensor(img):\n",
    "    img.shape=(img.shape[0],img.shape[1],1)\n",
    "    imgOut = torchvision.transforms.functional.to_tensor(img)\n",
    "    return imgOut\n",
    "\n",
    "def get_stratified_coords2D(box_size, shape):\n",
    "    coords = []\n",
    "    box_count_y = int(np.ceil(shape[0] / box_size))\n",
    "    box_count_x = int(np.ceil(shape[1] / box_size))\n",
    "    for i in range(box_count_y):\n",
    "        for j in range(box_count_x):\n",
    "            y = np.random.randint(0, box_size)\n",
    "            x = np.random.randint(0, box_size)\n",
    "            y = int(i * box_size + y)\n",
    "            x = int(j * box_size + x)\n",
    "            if (y < shape[0] and x < shape[1]):\n",
    "                coords.append((y, x))\n",
    "    return coords\n",
    "\n",
    "def jointShuffle(inA, inB):\n",
    "    dataTmp=np.concatenate( (inA[...,np.newaxis],inB[...,np.newaxis]) , axis=-1)\n",
    "    np.random.shuffle(dataTmp)\n",
    "    return dataTmp[...,0], dataTmp[...,1]\n",
    "\n",
    "def randomCropFRI(data, width, height, dataClean=None, counter=None):\n",
    "\n",
    "    if counter is None or counter>=data.shape[0]:\n",
    "        counter=0\n",
    "        if dataClean is not None:\n",
    "            data, dataClean=jointShuffle(data,dataClean)\n",
    "        else:\n",
    "            np.random.shuffle(data)\n",
    "    index=counter\n",
    "    counter+=1\n",
    "        \n",
    "    img=data[index]\n",
    "    if dataClean is not None:\n",
    "        imgClean = dataClean[index]\n",
    "    else:\n",
    "        imgClean = None\n",
    "    imgOut, imgOutC, mask =randomCrop(img, width, height, imgClean=imgClean)\n",
    "    return imgOut, imgOutC, mask, counter\n",
    "\n",
    "def randomCrop(img, width, height, imgClean=None, hotPixels=64):\n",
    "    assert img.shape[0] >= height\n",
    "    assert img.shape[1] >= width\n",
    "    \n",
    "    n2v=False\n",
    "    if imgClean is None:\n",
    "        imgClean=img.copy()\n",
    "        n2v=True\n",
    "\n",
    "    x = np.random.randint(0, img.shape[1] - width)\n",
    "    y = np.random.randint(0, img.shape[0] - height)\n",
    "    \n",
    "   \n",
    "    imgOut = img[y:y+height, x:x+width].copy()\n",
    "    imgOutC= imgClean[y:y+height, x:x+width].copy()  \n",
    "    mask=np.zeros(imgOut.shape)\n",
    "    maxA=imgOut.shape[1]-1\n",
    "    maxB=imgOut.shape[0]-1\n",
    "    \n",
    "    if n2v:\n",
    "        # Noise2Void training, i.e. no clean targets\n",
    "        hotPixels=get_stratified_coords2D(box_size,imgOut.shape)\n",
    "\n",
    "        for p in hotPixels:\n",
    "            a,b=p[1],p[0]\n",
    "\n",
    "            roiMinA=max(a-2,0)\n",
    "            roiMaxA=min(a+3,maxA)\n",
    "            roiMinB=max(b-2,0)\n",
    "            roiMaxB=min(b+3,maxB)\n",
    "            roi=imgOut[roiMinB:roiMaxB,roiMinA:roiMaxA]\n",
    "          #  print(roi.shape,b ,a)\n",
    "         #   print(b-2,b+3 ,a-2,a+3)\n",
    "            a_ = 2\n",
    "            b_ = 2\n",
    "            while a_==2 and b_==2:\n",
    "                a_ = np.random.randint(0, roi.shape[1] )\n",
    "                b_ = np.random.randint(0, roi.shape[0] )\n",
    "\n",
    "            repl=roi[b_,a_]\n",
    "            imgOut[b,a]=repl\n",
    "            mask[b,a]=1.0\n",
    "    else:\n",
    "        # Noise2Clean\n",
    "        mask[:] = 1.0\n",
    "\n",
    "    rot=np.random.randint(0,4)\n",
    "    imgOut=np.array(np.rot90(imgOut,rot))\n",
    "    imgOutC=np.array(np.rot90(imgOutC,rot))\n",
    "    mask=np.array(np.rot90(mask,rot))\n",
    "    if np.random.choice((True,False)):\n",
    "        imgOut=np.array(np.flip(imgOut))\n",
    "        imgOutC=np.array(np.flip(imgOutC))\n",
    "        mask=np.array(np.flip(mask))\n",
    "    \n",
    "    return imgOut, imgOutC, mask\n",
    "    \n",
    "\n",
    "def PSNR(gt, pred, range_=255.0 ):\n",
    "    mse = np.mean((gt - pred)**2)\n",
    "    return 20 * np.log10((range_)/np.sqrt(mse))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def normalize(img, mean, std):\n",
    "    zero_mean = img - mean\n",
    "    return zero_mean/std\n",
    "\n",
    "def denormalize(x, mean, std):\n",
    "    return x*std + mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the path to the input data\n",
    "path=\"/home/florian/projects/Fish/raw/\"\n",
    "\n",
    "# Training data\n",
    "data_raw=np.load(path+'training_big_raw.npy')\n",
    "data_gt=np.load(path+'../gt/training_big_GT.npy')\n",
    "#np.random.shuffle(data_raw)\n",
    "print(data_raw.shape)\n",
    "imgFactor=int(data_raw.shape[0]/data_gt.shape[0])\n",
    "print(imgFactor)\n",
    "index=604\n",
    "plt.imshow(data_raw[index])\n",
    "plt.show()\n",
    "plt.imshow(data_gt[index//imgFactor])\n",
    "plt.show()\n",
    "\n",
    "# Normalize\n",
    "mean=np.mean(data_raw)\n",
    "std=np.std(data_raw)\n",
    "print(mean,std)\n",
    "data=normalize(data_raw,mean,std)\n",
    "dataGT=normalize(data_gt,mean,std)\n",
    "dataGT=np.repeat(dataGT,imgFactor,axis=0)\n",
    "\n",
    "dataTest_raw=np.load(path+\"test_noisy.npy\")\n",
    "dataTest=normalize(dataTest_raw,mean,std)\n",
    "plt.imshow(dataTest_raw[5])\n",
    "\n",
    "dataTestGT=np.load(path+\"../gt/test_gt.npy\")\n",
    "print(dataTestGT[0].shape)\n",
    "plt.imshow(dataTestGT[0])\n",
    "print(mean,std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingPred(my_train_data, my_train_data_clean , dataCounter,size,bs):\n",
    "        # Init Variables\n",
    "        inputs= torch.zeros(bs,1,size,size)\n",
    "        labels= torch.zeros(bs,size,size)\n",
    "        masks= torch.zeros(bs,size,size)\n",
    "\n",
    "        # Assamble mini batch\n",
    "        for j in range(bs):\n",
    "            im,l,m, dataCounter=randomCropFRI(my_train_data,size,size,counter=dataCounter,dataClean=my_train_data_clean)\n",
    "            inputs[j,:,:,:]=imgToTensor(im)\n",
    "            labels[j,:,:]=imgToTensor(l)\n",
    "            masks[j,:,:]=imgToTensor(m)\n",
    "\n",
    "        # Move to GPU\n",
    "        inputs, labels, masks= inputs.to(device), labels.to(device), masks.to(device)\n",
    "\n",
    "        # Forward step \n",
    "        outputs = net(inputs)\n",
    "        return outputs, labels, masks, dataCounter\n",
    "    \n",
    "\n",
    "def lossFunction(outputs, labels, masks):\n",
    "    outs=outputs[:,0,...]\n",
    "    #print(outs.shape,labels.shape,masks.shape)\n",
    "    loss=torch.sum(masks*(labels-outs)**2)/torch.sum(masks)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as tdist\n",
    "import torch.optim as optim\n",
    "\n",
    "#data_c=np.concatenate((data.copy(),dataTest.copy()))\n",
    "data_c=data.copy()\n",
    "dataGT_c=dataGT.copy()\n",
    "data_c,dataGT_c=jointShuffle(data_c,dataGT_c)\n",
    "\n",
    "#my_train_data=data_c.copy()\n",
    "#my_val_data=data_c.copy()\n",
    "\n",
    "#my_train_dataGT=dataGT_c.copy()\n",
    "#my_val_dataGT=dataGT_c.copy()\n",
    "\n",
    "my_train_dataGT=None\n",
    "my_val_dataGT=None\n",
    "\n",
    "my_train_data=data_c.copy()\n",
    "my_val_data=data_c.copy()\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "net = UNet(1, depth=3)\n",
    "\n",
    "net.to(device)\n",
    "net.train(True)\n",
    "bs=24\n",
    "size=100\n",
    "num_pix=100*100/32.0\n",
    "dataCounter=None\n",
    "box_size = np.round(np.sqrt(size * size / num_pix)).astype(np.int)\n",
    "\n",
    "vbatch=20 # Virtual batch size\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.5, verbose=True)\n",
    "\n",
    "running_loss = 0.0\n",
    "stepCounter=0\n",
    "\n",
    "\n",
    "valSize=20\n",
    "stepsPerEpoch=1\n",
    "trainHist=[]\n",
    "valHist=[]\n",
    "\n",
    "for step in range(40000):  # loop over the dataset multiple times\n",
    "    losses=[]\n",
    "    optimizer.zero_grad()\n",
    "    stepCounter+=1\n",
    "     \n",
    "    # Iterate over virtual batch    \n",
    "    for a in range (vbatch):\n",
    "      \n",
    "        outputs, labels, masks, dataCounter = trainingPred(my_train_data, my_train_dataGT, dataCounter,size,bs)\n",
    "        \n",
    "        loss=lossFunction(outputs, labels,masks)\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        \n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    if stepCounter % stepsPerEpoch == stepsPerEpoch-1:\n",
    "        running_loss=(np.mean(losses))\n",
    "        print(\"Step:\", stepCounter, \"| Avg. epoch loss:\", running_loss)\n",
    "        losses=np.array(losses)\n",
    "        print(\"avg. loss: \"+str(np.mean(losses))+\"+-\"+str(np.std(losses)/np.sqrt(losses.size)))\n",
    "        trainHist.append(np.mean(losses))\n",
    "        losses=[]\n",
    "\n",
    "\n",
    "        torch.save(net,\"last\"+\".net\")\n",
    "\n",
    "        valCounter=0\n",
    "        net.train(False)\n",
    "        losses=[]\n",
    "        for i in range(valSize):\n",
    "            outputs, labels, masks, valCounter = trainingPred(my_val_data,my_val_dataGT, valCounter,size,bs)\n",
    "            loss=lossFunction(outputs, labels,masks)\n",
    "            losses.append(loss.item())\n",
    "        net.train(True)\n",
    "        avgValLoss=np.mean(losses)\n",
    "        if len(valHist)==0 or avgValLoss < np.min(valHist):\n",
    "            torch.save(net,\"best\"+\".net\")\n",
    "        valHist.append(avgValLoss)\n",
    "\n",
    "        epoch= (stepCounter / stepsPerEpoch)\n",
    "\n",
    "\n",
    "        np.save(\"history\"+\".npy\", (np.array( [np.arange(epoch),trainHist,valHist ] ) ) )\n",
    "\n",
    "        plt.plot(valHist)\n",
    "        plt.plot(trainHist)\n",
    "        plt.show()\n",
    "        scheduler.step(avgValLoss)\n",
    "        \n",
    "        if stepCounter / stepsPerEpoch > 200:\n",
    "            break\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(im, l):\n",
    "    inputs= torch.zeros(1,1,im.shape[0],im.shape[1])\n",
    "    inputs[0,:,:,:]=imgToTensor(im);  \n",
    "    \n",
    "    # copy to GPU\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    output=net(inputs)\n",
    "\n",
    "    samples=(output).permute(1, 0, 2, 3)\n",
    "    \n",
    "    means = samples[0,...] # Sum up over all samples\n",
    "    \n",
    "    # Get data from GPU\n",
    "    means=means.cpu().detach().numpy()\n",
    "\n",
    "    # Reshape to 2D images and remove padding\n",
    "    means.shape=(output.shape[2],output.shape[3])\n",
    "    \n",
    "    # Denormalize\n",
    "    means=denormalize(means,mean,std)\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import ndimage, misc\n",
    "\n",
    "results=[]\n",
    "meanRes=[]\n",
    "\n",
    "\n",
    "#load network\n",
    "net=torch.load(\"last.net\")\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "estimate=torch.tensor(25.0/std).to(device)\n",
    "for index in range(dataTest.shape[0]):\n",
    "\n",
    "    im=dataTest[index]\n",
    "    l=dataTestGT[0]\n",
    "    print(im.shape,l.shape)\n",
    "    means=np.zeros(im.shape)\n",
    "    mseEst=np.zeros(im.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # We have to use tiling because of memory constraints on the GPU\n",
    "    ps=128\n",
    "    overlap=48\n",
    "    xmin=0\n",
    "    ymin=0\n",
    "    xmax=ps\n",
    "    ymax=ps\n",
    "    ovLeft=0\n",
    "    while (xmin<im.shape[1]):\n",
    "        ovTop=0\n",
    "        while (ymin<im.shape[0]):     \n",
    "            a= predict(im[ymin:ymax,xmin:xmax],l[ymin:ymax,xmin:xmax])\n",
    "            means[ymin:ymax,xmin:xmax][ovTop:,ovLeft:] = a[ovTop:,ovLeft:]\n",
    "            ymin=ymin-overlap+ps\n",
    "            ymax=ymin+ps\n",
    "            ovTop=overlap//2\n",
    "        ymin=0 \n",
    "        ymax=ps\n",
    "        xmin=xmin-overlap+ps\n",
    "        xmax=xmin+ps\n",
    "        ovLeft=overlap//2\n",
    "    \n",
    "\n",
    "    im=denormalize(im,mean,std)\n",
    "    vmi=np.percentile(l,0.05)\n",
    "    vma=np.percentile(l,99.5)\n",
    "    print(vmi,vma)\n",
    "    \n",
    "    \n",
    "    psnrPrior=PSNR(l, means,255 )\n",
    "    results.append(psnrPrior)\n",
    "\n",
    "    \n",
    "    print (\"PSNR raw\",PSNR(l, im,255 ))\n",
    "    print (\"PSNR prior\",psnrPrior) # Without info from masked pixel\n",
    "    print (\"index\",index) \n",
    "    print (np.min(means),np.max(means))\n",
    "     \n",
    "    plt.imshow(im[200:328,200:328],cmap='gray',vmin=0,vmax=255) # GT\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(means[200:328,200:328],cmap='gray') # MSE estimate using the masked pixel\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "print(\"Avg Prior:\", np.mean(np.array(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
